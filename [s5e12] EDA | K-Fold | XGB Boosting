{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91723,"databundleVersionId":14272474,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/gourabr0y555/s5e12-eda-k-fold-xgb-boosting?scriptVersionId=289112960\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Season 5 Episode 12 Competition Notebook","metadata":{}},{"cell_type":"markdown","source":"We are tasked with producing the probabilities of a person being diagnosed with diabetes. I have tried to structure this notebook as well as possible, and I sincerely hope you can benefit from this.","metadata":{}},{"cell_type":"markdown","source":"## Other notebooks\n\n| Description | Link |\n| --- | --- |\n| Stacking or blending classification | https://www.kaggle.com/code/gourabr0y555/s5e12-stacking-blending-diabetes-predictions |\n| XGBoosting (this notebook) | https://www.kaggle.com/code/gourabr0y555/s5e12-eda-k-fold-xgb-boosting |\n| Catboosting for classification | https://www.kaggle.com/code/gourabr0y555/s5e12-eda-k-fold-cat-boosting |","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Imports and loading datasets","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:03.370238Z","iopub.execute_input":"2025-12-26T13:47:03.371115Z","iopub.status.idle":"2025-12-26T13:47:04.674324Z","shell.execute_reply.started":"2025-12-26T13:47:03.371081Z","shell.execute_reply":"2025-12-26T13:47:04.673645Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading datasets","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s5e12/train.csv')\ninference_df = pd.read_csv('/kaggle/input/playground-series-s5e12/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:04.675499Z","iopub.execute_input":"2025-12-26T13:47:04.675859Z","iopub.status.idle":"2025-12-26T13:47:07.387181Z","shell.execute_reply.started":"2025-12-26T13:47:04.675834Z","shell.execute_reply":"2025-12-26T13:47:07.386381Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"-----------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Null, duplicated, type, unique of columns","metadata":{}},{"cell_type":"markdown","source":"## Null check","metadata":{}},{"cell_type":"code","source":"train_df.isnull().values.any()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:07.388119Z","iopub.execute_input":"2025-12-26T13:47:07.388429Z","iopub.status.idle":"2025-12-26T13:47:07.607977Z","shell.execute_reply.started":"2025-12-26T13:47:07.388401Z","shell.execute_reply":"2025-12-26T13:47:07.607264Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Duplication check","metadata":{}},{"cell_type":"code","source":"train_df.duplicated().values.any()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:07.609465Z","iopub.execute_input":"2025-12-26T13:47:07.609739Z","iopub.status.idle":"2025-12-26T13:47:08.169009Z","shell.execute_reply.started":"2025-12-26T13:47:07.609703Z","shell.execute_reply":"2025-12-26T13:47:08.168262Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Type check","metadata":{}},{"cell_type":"code","source":"for cols in train_df.columns:\n    print(f\"{cols}: {train_df[cols].dtype}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:08.16991Z","iopub.execute_input":"2025-12-26T13:47:08.170214Z","iopub.status.idle":"2025-12-26T13:47:08.175348Z","shell.execute_reply.started":"2025-12-26T13:47:08.170181Z","shell.execute_reply":"2025-12-26T13:47:08.174711Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Unique value count","metadata":{}},{"cell_type":"code","source":"train_df.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:08.176341Z","iopub.execute_input":"2025-12-26T13:47:08.177069Z","iopub.status.idle":"2025-12-26T13:47:08.540328Z","shell.execute_reply.started":"2025-12-26T13:47:08.177032Z","shell.execute_reply":"2025-12-26T13:47:08.539603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Column type aggregation","metadata":{}},{"cell_type":"code","source":"num_col = [col for col in train_df.drop(['id', 'diagnosed_diabetes'], axis=1) if train_df[col].dtype in ['float64', 'int64']]\ncat_col = [col for col in train_df.drop(['id', 'diagnosed_diabetes'], axis=1) if train_df[col].dtype == 'object']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:08.541249Z","iopub.execute_input":"2025-12-26T13:47:08.541523Z","iopub.status.idle":"2025-12-26T13:47:08.714587Z","shell.execute_reply.started":"2025-12-26T13:47:08.541491Z","shell.execute_reply":"2025-12-26T13:47:08.713883Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Table description","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:08.715546Z","iopub.execute_input":"2025-12-26T13:47:08.715915Z","iopub.status.idle":"2025-12-26T13:47:09.182586Z","shell.execute_reply.started":"2025-12-26T13:47:08.715867Z","shell.execute_reply":"2025-12-26T13:47:09.18181Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"-----------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Correlation checks","metadata":{}},{"cell_type":"markdown","source":"## Pairplots","metadata":{}},{"cell_type":"code","source":"sns.pairplot(\n    data=train_df.sample(1000, random_state=42),\n    hue=\"diagnosed_diabetes\",\n    vars=[col for col in train_df.drop(['id'], axis=1) if len(train_df[col].unique()) > 100],\n)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:09.1836Z","iopub.execute_input":"2025-12-26T13:47:09.183964Z","iopub.status.idle":"2025-12-26T13:47:16.62768Z","shell.execute_reply.started":"2025-12-26T13:47:09.183939Z","shell.execute_reply":"2025-12-26T13:47:16.626626Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can see some positive correlation between a few columns. Some of them can be removed.","metadata":{}},{"cell_type":"markdown","source":"## Correlation heatmap and dropping columns","metadata":{}},{"cell_type":"markdown","source":"Highly correlated columns add redundancy to models, so all except one are necessary for training. As far columns with almost no correlation is concerened, they can't contribute much either.","metadata":{}},{"cell_type":"code","source":"df_x = train_df.drop(['id', 'diagnosed_diabetes'], axis=1)\ndf_y = pd.DataFrame({'diagnosed_diabetes': train_df.diagnosed_diabetes})\n\ninference_id = inference_df['id']\ninference_df.drop(['id'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:16.630254Z","iopub.execute_input":"2025-12-26T13:47:16.630516Z","iopub.status.idle":"2025-12-26T13:47:16.761705Z","shell.execute_reply.started":"2025-12-26T13:47:16.63049Z","shell.execute_reply":"2025-12-26T13:47:16.761059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\nencoder = OrdinalEncoder(categories=\"auto\")\nenc_ = pd.DataFrame(encoder.fit_transform(df_x[cat_col]), columns=cat_col)\ndf_x_ = pd.concat([df_x[num_col], enc_], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:16.762639Z","iopub.execute_input":"2025-12-26T13:47:16.762957Z","iopub.status.idle":"2025-12-26T13:47:17.846251Z","shell.execute_reply.started":"2025-12-26T13:47:16.762925Z","shell.execute_reply":"2025-12-26T13:47:17.845456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr = df_x_.corr()\nsns.heatmap(corr, cmap='coolwarm', linewidths=0.5, vmax=.3)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:17.847182Z","iopub.execute_input":"2025-12-26T13:47:17.847645Z","iopub.status.idle":"2025-12-26T13:47:19.37947Z","shell.execute_reply.started":"2025-12-26T13:47:17.847619Z","shell.execute_reply":"2025-12-26T13:47:19.378685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"upper = corr.abs().where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n\nto_drop = [column for column in upper.columns if any(upper[column]>0.8) or any(upper[column]<0.0002)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:19.380457Z","iopub.execute_input":"2025-12-26T13:47:19.380759Z","iopub.status.idle":"2025-12-26T13:47:19.390009Z","shell.execute_reply.started":"2025-12-26T13:47:19.380712Z","shell.execute_reply":"2025-12-26T13:47:19.389162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_x.drop(to_drop, axis=1, inplace=True)\ninference_df.drop(to_drop, axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:19.391019Z","iopub.execute_input":"2025-12-26T13:47:19.391376Z","iopub.status.idle":"2025-12-26T13:47:19.532636Z","shell.execute_reply.started":"2025-12-26T13:47:19.391351Z","shell.execute_reply":"2025-12-26T13:47:19.531977Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"-----------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Countplot","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=df_y, x='diagnosed_diabetes')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:19.533562Z","iopub.execute_input":"2025-12-26T13:47:19.533862Z","iopub.status.idle":"2025-12-26T13:47:20.783035Z","shell.execute_reply.started":"2025-12-26T13:47:19.533835Z","shell.execute_reply":"2025-12-26T13:47:20.782185Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Fairly balanced.","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Boxplots - finding outliers","metadata":{}},{"cell_type":"code","source":"df_x['hypertension_history'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:20.784117Z","iopub.execute_input":"2025-12-26T13:47:20.784441Z","iopub.status.idle":"2025-12-26T13:47:20.795898Z","shell.execute_reply.started":"2025-12-26T13:47:20.784408Z","shell.execute_reply":"2025-12-26T13:47:20.795172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Some are binary features. Outlier detection won't make sense in this.","metadata":{}},{"cell_type":"markdown","source":"## Boxplots","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(4, 12))\ni=1\n\nfor col in train_df.drop(['id', 'diagnosed_diabetes'], axis=1).columns:\n    if train_df[col].dtype != 'object' and len(train_df[col].unique()) > 6:\n        plt.subplot(5, 3, i)\n        plt.boxplot(train_df[col])\n        plt.title(f'plot for\\n{col}', fontsize=10)\n        i+=1\n    else:\n        continue\n        \nplt.tight_layout(rect=[0, 0.03, 2, 0.95])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:20.796983Z","iopub.execute_input":"2025-12-26T13:47:20.79729Z","iopub.status.idle":"2025-12-26T13:47:22.904063Z","shell.execute_reply.started":"2025-12-26T13:47:20.797265Z","shell.execute_reply":"2025-12-26T13:47:22.90331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Outlier removal","metadata":{}},{"cell_type":"code","source":"i=1\n\nfor col in df_x.columns:\n    if df_x[col].dtype != 'object' and len(df_x[col].unique()) > 5:\n        q1 = np.quantile(df_x[col], 0.25)\n        q3 = np.quantile(df_x[col], 0.75)\n        iqr = q3 - q1\n        \n        upper_bound = q3 + 1.5 * iqr\n        lower_bound = q1 - 1.5 * iqr\n        \n        values = df_x[col].to_numpy()\n        outliers = values[(values < lower_bound) | (values > upper_bound)]\n        print(\"{}. for {} there were {} outliers.\".format(i, col, len(outliers)))\n\n        df_x[col] = df_x[col].astype('float')\n        df_x.loc[df_x[col] < lower_bound, col] = lower_bound\n        df_x.loc[df_x[col] > upper_bound, col] = upper_bound\n        \n        i+=1\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:22.905079Z","iopub.execute_input":"2025-12-26T13:47:22.905324Z","iopub.status.idle":"2025-12-26T13:47:23.416532Z","shell.execute_reply.started":"2025-12-26T13:47:22.905302Z","shell.execute_reply":"2025-12-26T13:47:23.415684Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Outliers are removed. Re-run the above cell to check if there are any outliers present or not.","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Training, Testing and Inference","metadata":{}},{"cell_type":"markdown","source":"## Column re-categorization","metadata":{}},{"cell_type":"code","source":"num_col = [col for col in df_x.columns if df_x[col].dtype != 'object']\ncat_col = [col for col in df_x.columns if df_x[col].dtype == 'object']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:47:23.41752Z","iopub.execute_input":"2025-12-26T13:47:23.417806Z","iopub.status.idle":"2025-12-26T13:47:23.422681Z","shell.execute_reply.started":"2025-12-26T13:47:23.417781Z","shell.execute_reply":"2025-12-26T13:47:23.421951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n# Another is StratifiedShuffleSplit, where the shuffling happens before each split, so there may be overlap of test sets\n# In our case, we will use StratifiedKFold; there is shuffling just once before splitting, so no overlap of test sets\n\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nimport xgboost as xgb\n\n\nmodel_xgb = xgb.XGBClassifier()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:56:41.842581Z","iopub.execute_input":"2025-12-26T13:56:41.84343Z","iopub.status.idle":"2025-12-26T13:56:41.847896Z","shell.execute_reply.started":"2025-12-26T13:56:41.843396Z","shell.execute_reply":"2025-12-26T13:56:41.847127Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pipelines","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\n\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),         # as there are no null values this wouldn't be needed but it's a good practice to include this\n    ('scaler', StandardScaler()),\n])\n\ncat_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"most_frequent\")),  # same here, good practice to include\n    ('ord_enc', OrdinalEncoder(categories=\"auto\")),\n])\n\npre_processing = ColumnTransformer(transformers=[\n    ('num', num_pipeline, num_col),\n    ('cat', cat_pipeline, cat_col),\n])\n\nmodel = Pipeline([\n    ('preprocess', pre_processing),\n    ('classifier', model_xgb),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:56:43.438463Z","iopub.execute_input":"2025-12-26T13:56:43.43906Z","iopub.status.idle":"2025-12-26T13:56:43.458366Z","shell.execute_reply.started":"2025-12-26T13:56:43.43903Z","shell.execute_reply":"2025-12-26T13:56:43.457648Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train-test split and hypertuning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\n\n\nX_train, X_test, y_train, y_test = train_test_split(df_x,\n                                                    df_y,\n                                                    test_size=0.2,\n                                                    shuffle=True,\n                                                    random_state=42)\n\nparam_grid = {\n    'classifier__eta': [0.2, 0.25, 0.3, 0.35,],\n    'classifier__gamma': [0, 0.5, 1],\n    'classifier__max_depth': [5, 6, 7],\n}\n\ngrid = GridSearchCV(\n    estimator=model,\n    param_grid=param_grid,\n    cv=StratifiedKFold(5),\n    scoring=\"roc_auc\",\n    n_jobs=-1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:57:05.884395Z","iopub.execute_input":"2025-12-26T13:57:05.884842Z","iopub.status.idle":"2025-12-26T13:57:06.203248Z","shell.execute_reply.started":"2025-12-26T13:57:05.884811Z","shell.execute_reply":"2025-12-26T13:57:06.202383Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training and testing","metadata":{}},{"cell_type":"code","source":"grid.fit(X_train, y_train)\n\ny_pred = grid.predict_proba(X_test)\n\nroc_score = roc_auc_score(y_test, y_pred[:, 1])\n\nprint(f\"\\nROC score: {roc_score}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T13:57:10.592366Z","iopub.execute_input":"2025-12-26T13:57:10.593203Z","iopub.status.idle":"2025-12-26T14:06:30.323913Z","shell.execute_reply.started":"2025-12-26T13:57:10.593169Z","shell.execute_reply":"2025-12-26T14:06:30.323003Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Make predictions on the final test set","metadata":{}},{"cell_type":"code","source":"preds = grid.predict_proba(\n    inference_df\n)\n\n\ndata = pd.DataFrame({\n    'id': inference_id,\n    'diagnosed_diabetes': preds[:, 1]\n})\n\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T14:06:30.325365Z","iopub.execute_input":"2025-12-26T14:06:30.325644Z","iopub.status.idle":"2025-12-26T14:06:31.116964Z","shell.execute_reply.started":"2025-12-26T14:06:30.325619Z","shell.execute_reply":"2025-12-26T14:06:31.116118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.to_csv(\n    'submission.csv',\n    index=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T14:06:31.117947Z","iopub.execute_input":"2025-12-26T14:06:31.118239Z","iopub.status.idle":"2025-12-26T14:06:31.577712Z","shell.execute_reply.started":"2025-12-26T14:06:31.118214Z","shell.execute_reply":"2025-12-26T14:06:31.577054Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I hope you learned something üí° and enjoyed my notebook. Leave a upvote üëç, it will encourage me to share more code with the community.","metadata":{}},{"cell_type":"markdown","source":"-----------------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------------\n","metadata":{}}]}